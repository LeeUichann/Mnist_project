# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yr9nqwu2FtPiFhIA6C9yqkF4ZSzy0TNH
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
class LeNet5(nn.Module):

    def __init__(self):

        super(LeNet5,self).__init__()
        self.conv1 = nn.Conv2d(1,6,5)
        self.bn1 = nn.BatchNorm2d(6)
        self.maxpool1 = nn.MaxPool2d(2,2)
        self.conv2 = nn.Conv2d(6,16,5)
        self.bn2 = nn.BatchNorm2d(16)
        self.maxpool2 = nn.MaxPool2d(2,2)
        self.conv3 = nn.Conv2d(16,120,5)
        self.bn3 = nn.BatchNorm2d(120)

        self.fc1 = nn.Linear(120,84)
        self.fc2 = nn.Linear(84,10)

        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.5)






    def forward(self,x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.maxpool2(x)
        x = self.conv3(x)
        x = self.bn3(x)
        x = self.relu(x)
        x = torch.flatten(x,1)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)

        return x


class customMLP(nn.Module):

    def __init__(self):
        super(customMLP, self).__init__()
        self.fc1 = nn.Linear(32*32,60)
        self.fc2 = nn.Linear(60,10)

        self.relu = nn.ReLU()

    def forward(self,x):
        x = torch.flatten(x, 1)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)

        return x